{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `ipcmagic` with TensorFlow-1 and Horovod\n",
    "\n",
    " * The two nodes have different names\n",
    " * Both nodes are using the GPU (the GPU usage is about 3%).\n",
    " * The training time last just a couple of seconds.\n",
    " * After running `ipcluster stop` the GPU memory ussage goes to zero.\n",
    " \n",
    " > To run this notebook it's necessary to have the Horovod module loaded. Please add the following on the `$HOME/.jupyterhub.env` file\n",
    " ```bash\n",
    "  module load Horovod/0.16.4-CrayGNU-19.10-tf-1.14.0\n",
    " ```\n",
    " Please, make sure that it doesn't conflict with any other line that you might have on your `$HOME/.jupyterhub.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcmagic.local\n",
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster start -n 2 --mpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ipp.Client()   # (profile='job_17669451')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import socket\n",
    "socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Note that the generated rando data is different from one node to the other\n",
    "nsamples = 1000\n",
    "ref_slope = 2.0\n",
    "ref_offset = 0.0\n",
    "noise = np.random.random((nsamples, 1)) - 0.5\n",
    "x_train = np.random.random((nsamples, 1)) - 0.5\n",
    "y_train = ref_slope * x_train + ref_offset + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "#input pipeline\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train.astype(np.float32),\n",
    "                                              y_train.astype(np.float32)))\n",
    "dataset = dataset.shard(hvd.size(), hvd.rank())\n",
    "dataset = dataset.batch(500)\n",
    "dataset = dataset.repeat(100)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Define the model\n",
    "slope = tf.Variable(np.random.randn())\n",
    "offset = tf.Variable(np.random.randn())\n",
    "\n",
    "x, y = next_item  # The model is the continuation of the pipeline\n",
    "\n",
    "y_hat = slope * x + offset\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_hat, y)\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(.5)\n",
    "train = hvd.DistributedOptimizer(opt).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "hooks = [hvd.BroadcastGlobalVariablesHook(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "history = []\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(hooks=hooks) as sess:\n",
    "    # Initialization of the variables `slope` and `offset`\n",
    "    # is done automatically by tf.train.MonitoredTrainingSession\n",
    "    print('rank', hvd.rank(),\n",
    "          'inital slope   = %12.6f\\n       initial offset = %12.6f' %\n",
    "          sess.run((slope, offset)))\n",
    "    while not sess.should_stop():\n",
    "        _, loss_val, m, n = sess.run((train, loss, slope, offset))\n",
    "        history.append([sess.run(slope), sess.run(offset), loss_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the SGD\n",
    "\n",
    "Plot the path taken by the SGD during training. This shows the path taken by both workers. They must be identical, if they aren't, it means that something on the distributed SGD algorithm went wrong.\n",
    "\n",
    ">To plot the path individually, the options `--target 0` and `--target 1` of `%%px` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def loss_function_field(m, n, xref, yref):\n",
    "    return np.mean(np.square(yref - m * xref - n))\n",
    "\n",
    "\n",
    "slope_hist = np.array(history)[:, 0]\n",
    "offset_hist = np.array(history)[:, 1]\n",
    "\n",
    "# Create [slope x offset] grid for contour plot\n",
    "_m = np.arange(-0, 4.01, 0.1)\n",
    "_n = np.arange(-0.5, 0.51, 0.1)\n",
    "M, N = np.meshgrid(_m, _n)\n",
    "\n",
    "Z = np.zeros(M.shape)\n",
    "for i in range(M.shape[0]):\n",
    "    for j in range(M.shape[1]):\n",
    "        Z[i, j] = loss_function_field(M[i, j], N[i, j],\n",
    "                                      x_train, y_train)\n",
    "\n",
    "# matplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "\n",
    "cp = plt.contour(M, N, Z, 50, vmin=Z.min(), vmax=Z.max(), alpha=0.4)\n",
    "plt.clabel(cp, cp.levels[:6])\n",
    "plt.colorbar()\n",
    "m = slope_hist[-1]\n",
    "n = offset_hist[-1]\n",
    "plt.plot(slope_hist, offset_hist, '.-', lw=1)\n",
    "plt.plot([ref_slope], [ref_offset], 'rx', ms=10)\n",
    "plt.xlim([_m.min(), _m.max()])\n",
    "plt.ylim([_n.min(), _n.max()])\n",
    "plt.xlabel('Slope')\n",
    "plt.ylabel('Offset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
