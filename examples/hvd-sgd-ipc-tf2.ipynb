{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Stochastic Gradient Descent in Two Nodes with TensorFlow, Horovod and IPCMagic.\n",
    "\n",
    "Here we visualize the minimization of the loss with the SGD algorithm.\n",
    "For this, we consider a linear model with only two weights (the slope and the offset).\n",
    "\n",
    "With this example we show how use IPCMagic to run TensorFlow in two nodes from a Jupyter notebook.\n",
    "We consider blocking and non-blocking execution of code on the IPCluster.\n",
    "We also show how to combine non-blocking execution and the function `ipcmagic.utilities.watch_asyncresult` to have real-time logging during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcmagic\n",
    "from ipcmagic import utilities   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster start -n 2 --launcher srun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In cells that take some time, IPyParallel shows a progress bar.\n",
    "# That can be disabled with by passing `--progress-after -1` to `%%px`.\n",
    "%pxconfig --progress-after -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import socket\n",
    "socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow.keras as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Create a linear function with noise as our data\n",
    "nsamples = 1000\n",
    "ref_slope = 2.0\n",
    "ref_offset = 0.0\n",
    "noise = np.random.random((nsamples, 1)) - 0.5    # -0.5 to center the noise\n",
    "x_train = np.random.random((nsamples, 1)) - 0.5  # -0.5 to center x around 0\n",
    "y_train = ref_slope * x_train + ref_offset + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train.astype(np.float32),\n",
    "                                              y_train.astype(np.float32)))\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(100)\n",
    "dataset = dataset.repeat(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(1,), activation='linear'),\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(lr=0.5)\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "class TrainHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.vars = []\n",
    "        self.loss = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.vars.append([v.numpy() for v in self.model.variables])\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        \n",
    "history = TrainHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "initial_sync = hvd.callbacks.BroadcastGlobalVariablesCallback(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cells we have been using the default execution mode of IPyParallel, which is blocking.\n",
    "That means that the cell will be busy until the execution is over and the output of the cell will be visible only when the run finishes.\n",
    "\n",
    "In the next cell, which takes some seconds to finish, we run `model.fit(...)` which shows an animation where we can see the progress of the training.\n",
    "In blocking mode, we won't see the progress, only the final result.\n",
    "To see the animation, we can use the non-blocking execution together with `ipcmagic.utilities.watch_asyncresult` which lets us see the output as it's produced.\n",
    "Non-blocking execution can be specified by passing the option `--noblock` to `%%px`.\n",
    "\n",
    "In non-blocking execution, the cell will exit inmediatelly, returning an `AsyncResult` object.\n",
    "That object is needed by the `ipcmagic.utilities.watch_asyncresult` function.\n",
    "To get the output of a cell in a python variable (let's call it `my_async_result`), we need to pass the option `-o my_async_result` to `%%px`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --noblock -o training_async_result\n",
    "\n",
    "# the non-blocking execution (`%%px --noblock`) returns an `AsyncResult` object inmediately.\n",
    "# the `AsyncResult` object can be accessed from python with the option `-o <variable>`.\n",
    "# by doing that we can fetch information while the code running.\n",
    "\n",
    "fit = model.fit(dataset, callbacks=[initial_sync, history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch the output in real time\n",
    "utilities.watch_asyncresult(training_async_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "slope_hist = np.array(history.vars)[:, 0]\n",
    "offset_hist = np.array(history.vars)[:, 1]\n",
    "loss_hist = np.array(history.loss)\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8, 3)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_hist[10:], 'r.-')\n",
    "plt.xlabel('Training steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_train, y_train, '.')\n",
    "plt.plot(x_train, slope_hist[-1] * x_train + offset_hist[-1], 'r-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "def loss_function_field(m, n, xref, yref):\n",
    "    '''Utility function for ploting the loss'''\n",
    "    return np.mean(np.square(yref - m * xref - n ))\n",
    "\n",
    "_m = np.arange(-0.0, 4.01, 0.1)\n",
    "_n = np.arange(-0.5, 0.51, 0.1)\n",
    "M, N = np.meshgrid(_m, _n)\n",
    "\n",
    "Z = np.zeros(M.shape)\n",
    "for i in range(M.shape[0]):\n",
    "    for j in range(M.shape[1]):\n",
    "        Z[i, j] = loss_function_field(M[i, j], N[i, j],\n",
    "                                      x_train, y_train)\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 7)\n",
    "\n",
    "cp = plt.contour(M, N, Z, 15, vmin=Z.min(), vmax=Z.max(), alpha=0.99, colors='k', linestyles='--')\n",
    "plt.contourf(M, N, Z, vmin=Z.min(), vmax=Z.max(), alpha=0.8, cmap=plt.cm.RdYlBu_r)\n",
    "plt.clabel(cp, cp.levels[:6])\n",
    "plt.colorbar()\n",
    "m = slope_hist[-1]\n",
    "n = offset_hist[-1]\n",
    "plt.plot(slope_hist, offset_hist, '.-', lw=2, c='k')\n",
    "plt.plot([ref_slope], [ref_offset], 'rx', ms=10)\n",
    "plt.xlim([_m.min(), _m.max()])\n",
    "plt.ylim([_n.min(), _n.max()])\n",
    "plt.xlabel('Slope')\n",
    "plt.ylabel('Offset')\n",
    "plt.show()\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-multigpu",
   "language": "python",
   "name": "tf-multigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
